================================================================================
MENTORA v2.0 - QUICK START GUIDE
================================================================================

ğŸš€ GET STARTED IN 5 MINUTES

================================================================================
WHAT'S NEW IN V2.0
================================================================================

âœ¨ REAL-TIME FACIAL EMOTION DETECTION
   Live webcam analysis using face-api.js
   Emotions: Happy, Focused, Neutral, Calm, Stressed, Tired, Sad, Confused, Anxious

âœ¨ NO LOGIN REQUIRED
   Anonymous sessions auto-created on app load
   Jump straight into learning experience

âœ¨ EMOTION-AWARE RESPONSES
   AI adapts tone, length, and style based on your feelings
   Happy students get energetic explanations
   Stressed students get calm, supportive guidance

âœ¨ MULTI-MODAL EMOTION DETECTION
   Combines facial expression + voice tone + text sentiment
   More accurate than any single source

âœ¨ SMART BREAK RECOMMENDATIONS
   System suggests breaks when fatigue detected
   Personalized activities based on current emotion

================================================================================
INSTALLATION (3 STEPS)
================================================================================

STEP 1: Install Dependencies
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cd frontend
npm install

cd ../Backed_Flask
pip install -r requirements.txt

STEP 2: Start Servers
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Terminal 1:
cd Backed_Flask && python app.py
â†’ Backend running on http://127.0.0.1:5000

Terminal 2:
cd frontend && npm run dev
â†’ Frontend running on http://localhost:5173

STEP 3: Open Browser
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Open: http://localhost:5173
Allow camera access when prompted
Start learning!

================================================================================
HOW TO USE
================================================================================

1. CAMERA ACCESS
   When app loads, browser asks for camera permission
   Click "Allow" to enable facial emotion detection
   You can disable camera anytime via button in interface

2. ASK QUESTIONS
   - Type a question or speak via microphone
   - System detects your facial emotion in real-time
   - Response adapts based on how you're feeling

3. WATCH EMOTION DETECTION
   - Webcam feed shows in top-right or sidebar
   - Emoji displays current emotion (ğŸ˜Š ğŸ˜ ğŸ˜£ etc.)
   - Confidence percentage updates live

4. GET PERSONALIZED HELP
   - Stressed? Get calm, supportive explanations
   - Happy? Get energetic, detailed responses
   - Tired? Get brief, simple explanations
   - Confused? Get step-by-step breakdowns

5. TAKE BREAKS
   If studying for 45+ minutes with signs of fatigue
   System suggests: stretching, meditation, water break

================================================================================
KEY FILES TO UNDERSTAND
================================================================================

FRONTEND:
src/services/facialEmotionDetector.ts
  â†’ Real-time facial emotion detection
  â†’ Reads: webcam feed
  â†’ Outputs: emotion + confidence

src/components/WebcamCapture.tsx
  â†’ Webcam display component
  â†’ Shows live video + emotion overlay
  â†’ Start/stop detection button

src/services/multiModalEmotionContext.ts
  â†’ Merges facial + voice + text emotion
  â†’ Calculates unified emotion state
  â†’ Provides response guidelines per emotion

src/main.tsx
  â†’ Initializes anonymous Firebase session on load
  â†’ No login screen needed

BACKEND:
services/emotion_aware_responses.py
  â†’ Adapts Gemini responses for emotion
  â†’ Generates emotion-aware explanations
  â†’ Formats responses with emotional context

routes/ask.py, voice.py, emotion.py
  â†’ Should pass emotion context to AI
  â†’ Should use emotion for voice settings
  â†’ Should suggest breaks based on emotion

================================================================================
EMOTION REFERENCE GUIDE
================================================================================

ğŸ˜Š HAPPY (High Engagement)
  You feel:        Joyful, energized, positive
  System responds: Energetic tone, detailed explanations, encouraging
  Break needed:    No (keep momentum!)
  Voice:           High pitch, fast pace

ğŸ˜ NEUTRAL (Baseline)
  You feel:        Normal, balanced, learning-focused
  System responds: Professional tone, standard explanations
  Break needed:    No
  Voice:           Medium pitch, normal pace

ğŸ¯ FOCUSED (Deep Learning)
  You feel:        Concentrated, engaged, determined
  System responds: Clear, structured, comprehensive
  Break needed:    No (great time to learn!)
  Voice:           Medium pitch, normal pace

ğŸ˜Œ CALM (Relaxed)
  You feel:        Peaceful, steady, at ease
  System responds: Soothing tone, supportive, normal detail
  Break needed:    No
  Voice:           Medium pitch, slow pace

ğŸ˜£ STRESSED (Anxious)
  You feel:        Overwhelmed, tense, under pressure
  System responds: Calm tone, SHORT sentences, reassuring
  Break needed:    YES! 2-min break recommended
  Voice:           Low pitch, slow pace

ğŸ˜´ TIRED (Low Energy)
  You feel:        Exhausted, fatigue, low energy
  System responds: Supportive tone, BRIEF explanations, simple words
  Break needed:    YES! 5-10 min break + stretch
  Voice:           Medium pitch, slow pace

ğŸ˜¢ SAD (Low Mood)
  You feel:        Down, melancholy, discouraged
  System responds: Compassionate tone, SHORT explanations, encouragement
  Break needed:    YES! Take time for yourself
  Voice:           Medium pitch, calm tone

ğŸ˜• CONFUSED (Uncertain)
  You feel:        Lost, uncertain, puzzled
  System responds: Patient tone, DETAILED step-by-step, analogies
  Break needed:    No (clarity coming!)
  Voice:           Medium pitch, normal pace

ğŸ˜° ANXIOUS (Nervous)
  You feel:        Worried, nervous, apprehensive
  System responds: Grounding tone, concise, reassuring, supportive
  Break needed:    YES! Breathing exercise suggested
  Voice:           Low pitch, slow pace

================================================================================
API ENDPOINTS THAT ACCEPT EMOTION
================================================================================

POST /api/ask-question
  Body: { question: string, emotion: string, confidence: number }
  Returns: Emotion-aware response

POST /api/summarize
  Body: { text: string, emotion: string }
  Returns: Summary adapted to emotion

POST /api/text-to-speech
  Body: { text: string, emotion: string, voice_id: string }
  Returns: Audio with emotion-appropriate tone

GET /api/break-suggestions/:emotion
  Returns: Emotion-specific break activities

POST /api/detect-emotion
  Body: { text: string, duration: string }
  Returns: Emotion analysis + recommendations

================================================================================
EXAMPLE INTERACTIONS
================================================================================

SCENARIO 1: Happy Student
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Student: *Smiling, makes "YES" gesture*
System detects: HAPPY (92% confidence)
Student asks: "How does photosynthesis work?"

Response:
"That's an AWESOME question! ğŸŒŸ 
Let me show you the incredible process of photosynthesis!

It's basically how plants turn SUNLIGHT into FOOD. Here's the full breakdown:
1. Light energy hits the chloroplast
2. Water molecules split (photolysis)
3. Electrons get excited (they LOVE sunlight!)
4. ATP and NADPH are created
5. CO2 is converted to glucose

You're doing GREAT asking these questions! Keep it up! ğŸ’ª"

Voice: High pitch, energetic, celebratory tone

SCENARIO 2: Stressed Student
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Student: *Tense expression, looking down*
System detects: STRESSED (85% confidence)
Student types: "I don't get this at all"

System suggests: "Let's take a calming breath first..."

Response:
"I understand. You've got this. Let's slow down.

Photosynthesis is simple: 
Plants turn sunlight into food.

That's the main idea. Ready for the details? We'll take it step by step."

UI colors: Shift to calm blue/purple
Voice: Low pitch, slow, reassuring tone
Suggestion: "Try a 2-minute breathing break first"

SCENARIO 3: Tired Student
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Student: *Droopy eyes, been studying 90 minutes*
System detects: TIRED (80% confidence)
Session duration: 90 minutes
System alert: "BREAK TIME! â˜•"

Response to question:
"Good question. Simply:
- Plants use sunlight
- They make sugar from it
- That's photosynthesis!

Take a break now - walk, stretch, water.
Come back refreshed! â˜ºï¸"

Suggestions:
- 10-minute walk
- Grab water
- Stretch routine

UI colors: Shift to warm, inviting colors
Voice: Slow, supportive tone
Break timer: Suggests return in 10 min

================================================================================
TESTING THE SYSTEM
================================================================================

TEST 1: Facial Detection
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Open app, allow camera
2. Make different faces:
   - Smile â†’ "happy" shows
   - Neutral â†’ "neutral" shows
   - Angry face â†’ "stressed" shows
   - Yawning â†’ "tired" shows
3. Confidence percentage should update smoothly
4. No flickering (smoothing works)

TEST 2: Response Adaptation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Make happy face, ask a question
2. Note: Response is energetic and detailed
3. Look neutral, ask same question
4. Note: Response is more matter-of-fact
5. Look stressed, ask same question
6. Note: Response is calm and brief

TEST 3: Break Suggestions
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Study for 45+ minutes
2. Show tired/stressed expression
3. Verify: Break suggestion appears
4. Click break timer
5. Verify: Countdown starts, then suggests resume

TEST 4: Voice Adaptation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Ask question while happy
2. Listen to voice response (energetic tone)
3. Ask same question while stressed
4. Listen to voice response (calm tone)
5. Verify: Tone/pitch changes with emotion

================================================================================
TROUBLESHOOTING
================================================================================

CAMERA NOT WORKING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Camera permission denied or no video showing
Solution:
âœ“ Check browser allows camera (check address bar permissions)
âœ“ Ensure camera works (test in other app)
âœ“ Try different browser (Chrome recommended)
âœ“ Check privacy/security settings
âœ“ Disable browser extensions that block camera

EMOTION NOT DETECTING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: "Neutral" emotion stuck even when making faces
Solution:
âœ“ Ensure good lighting (not too dark or backlit)
âœ“ Remove sunglasses/hats
âœ“ Make clear facial expressions (not subtle)
âœ“ Check console for errors (F12)
âœ“ Try different browser/device

RESPONSES NOT CHANGING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Responses same regardless of emotion
Solution:
âœ“ Verify emotion being detected (check label in video)
âœ“ Check backend is receiving emotion parameter
âœ“ Verify emotion_aware_responses.py imported
âœ“ Check console logs for errors
âœ“ Test with obvious emotions (happy vs stressed)

VOICE SOUNDS WRONG
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: Voice tone doesn't match emotion
Solution:
âœ“ Verify emotion parameter sent to /api/text-to-speech
âœ“ Check ElevenLabs API key in .env
âœ“ Test voice generation directly
âœ“ Try different voice IDs
âœ“ Check browser audio settings

LAG OR SLOWDOWN
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Problem: UI sluggish, emotions update slowly
Solution:
âœ“ Check CPU usage (might be maxed)
âœ“ Close other browser tabs
âœ“ Reduce video resolution
âœ“ Check GPU acceleration enabled
âœ“ Reduce detection frequency (edit interval in detector)

================================================================================
PERFORMANCE NOTES
================================================================================

First Load Time: ~30 seconds
  - Models loading from CDN (~30MB)
  - Cached after first load (~1s on subsequent loads)

Detection Latency: ~200ms
  - Face detection: ~100ms
  - Expression analysis: ~50ms
  - Smoothing/averaging: ~50ms
  - UI update: instant

Memory Usage: ~200-300MB
  - TensorFlow models in memory
  - Webcam stream buffering
  - Emotion history (last 50 frames)

GPU Acceleration: Recommended
  - Significantly faster emotion detection
  - Lower CPU usage
  - Smoother real-time performance

Mobile Performance: Variable
  - iOS Safari: Good (if HTTPS)
  - Android Chrome: Good
  - Older devices: May be slower
  - Battery usage: ~5-10% impact

================================================================================
PRIVACY & SECURITY
================================================================================

NO FACE DATA IS STORED
âœ“ Only emotion labels stored ("happy", "stressed", etc.)
âœ“ No images or video recorded
âœ“ No face recognition/identification
âœ“ Raw expression data deleted immediately

EMOTION DATA IS KEPT
âœ“ Emotion labels + confidence stored in Firebase
âœ“ Used for analytics and personalization
âœ“ Associated with session, not identified to person
âœ“ Can be deleted by user

CAMERA IS OPTIONAL
âœ“ App works without camera enabled
âœ“ Can disable/enable anytime
âœ“ No data collected if camera off

ENCRYPTED
âœ“ All data sent over HTTPS
âœ“ Firebase encryption at rest
âœ“ No unencrypted storage of emotion data

================================================================================
NEXT FEATURES (ROADMAP)
================================================================================

v2.1 - POSTURE & ENGAGEMENT
  Detect posture via camera (slouching = fatigue)
  Track eye gaze (looking away = distraction)
  Micro-expressions (fleeting emotions)

v2.2 - VOICE STRESS ANALYSIS
  Analyze voice tone, pitch, stress
  Combine with text sentiment
  Better emotion accuracy

v2.3 - LONG-TERM PATTERNS
  Learn student's emotion baseline
  Predict when breaks needed
  Personalized emotion thresholds

v2.4 - SOCIAL LEARNING
  Share emotion insights with tutor
  Group study emotion tracking
  Peer support recommendations

v2.5 - WEARABLE INTEGRATION
  Connect fitness trackers
  Heart rate variability
  Sleep quality tracking

================================================================================
SUPPORT RESOURCES
================================================================================

Documentation:
- IMPLEMENTATION_GUIDE_V2.txt (detailed technical guide)
- PROJECT_DOCUMENTATION.txt (full system documentation)
- Code comments (each service well-documented)

Code Examples:
- See integration examples in IMPLEMENTATION_GUIDE_V2.txt
- Check existing components for patterns
- Review emotion profiles in emotion_aware_responses.py

Debugging:
- Browser Console (F12) for errors
- Network Tab to check API calls
- React DevTools for component state
- Check emotion label in WebcamCapture

Community:
- GitHub Issues for bugs
- GitHub Discussions for questions
- Pull requests welcome

================================================================================
YOU'RE READY! ğŸš€
================================================================================

1. Install dependencies
2. Start both servers
3. Open http://localhost:5173
4. Allow camera
5. Start learning with emotion-aware AI

The system will detect your emotions and adapt everything:
- How it explains concepts
- The tone of voice it uses
- When it suggests breaks
- How encouraging it is
- Even the colors on screen

Enjoy your emotion-aware learning experience!

Questions? Check the IMPLEMENTATION_GUIDE_V2.txt for detailed technical info.

Happy learning! ğŸ“šâœ¨
